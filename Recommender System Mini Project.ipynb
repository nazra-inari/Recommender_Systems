{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix as sparse_matrix\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "We'll be using the [Amazon product data set](http://jmcauley.ucsd.edu/data/amazon/). The author of the data set has asked for the following citations:\n",
    "\n",
    "> Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering.\n",
    "> R. He, J. McAuley.\n",
    "> WWW, 2016.\n",
    "> \n",
    "> Image-based recommendations on styles and substitutes.\n",
    "> J. McAuley, C. Targett, J. Shi, A. van den Hengel.\n",
    "> SIGIR, 2015.\n",
    "\n",
    "We will focus on the Patio, Lawn, and Garden section. Please download the [ratings](http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Patio_Lawn_and_Garden.csv) and place them in the data directory with their default filenames. The code below should load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2VNYWOPJ13AFP</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1259798400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A20DWVV8HML3AW</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1371081600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3RVP3YBYYOPRH</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1257984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A28XY55TP3Q90O</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1314144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3VZW1BGUQO0V3</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1308268800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user        item  rating   timestamp\n",
       "0  A2VNYWOPJ13AFP  0981850006     5.0  1259798400\n",
       "1  A20DWVV8HML3AW  0981850006     5.0  1371081600\n",
       "2  A3RVP3YBYYOPRH  0981850006     5.0  1257984000\n",
       "3  A28XY55TP3Q90O  0981850006     5.0  1314144000\n",
       "4  A3VZW1BGUQO0V3  0981850006     5.0  1308268800"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"/Users/arzan/MDS/ratings_Patio_Lawn_and_Garden.csv\"\n",
    "\n",
    "with open(os.path.join(\"data\", filename), \"rb\") as f:\n",
    "    ratings = pd.read_csv(f,names=(\"user\",\"item\",\"rating\",\"timestamp\"))\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd also like to construct the data matrix `X`. Let's see how big it would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 993490\n",
      "The average rating: 4.006400668350965\n",
      "Number of users: 714791\n",
      "Number of items: 105984\n",
      "Fraction nonzero: 1.3114269915944552e-05\n",
      "Size of full X matrix (GB): 606.051274752\n"
     ]
    }
   ],
   "source": [
    "def get_stats(ratings, item_key=\"item\", user_key=\"user\"):\n",
    "    print(\"Number of ratings:\", len(ratings))\n",
    "    print(\"The average rating:\", np.mean(ratings[\"rating\"]))\n",
    "\n",
    "    n = len(set(ratings[item_key]))\n",
    "    d = len(set(ratings[user_key]))\n",
    "    print(\"Number of users:\", d)\n",
    "    print(\"Number of items:\", n)\n",
    "    print(\"Fraction nonzero:\", len(ratings)/(n*d))\n",
    "    print(\"Size of full X matrix (GB):\", (n*d)*8/1e9)\n",
    "\n",
    "    return n,d\n",
    "\n",
    "n,d = get_stats(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "600 GB! That is way too big. We don't want to create that matrix. On the other hand, we see that we only have about 1 million ratings, which would be 8 MB or so ($10^6$ numbers $\\times$ 8 bytes per number). Much more manageable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(ratings, n, d, user_key=\"user\", item_key=\"item\"):\n",
    "    \"\"\"\n",
    "    Creates a sparse matrix using scipy.csr_matrix and mappers to relate indexes to items' id.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ratings: the ratings to be stored in the matrix;\n",
    "    n: the number of items\n",
    "    d: the number of users\n",
    "    user_key: the column in the pandas dataframe that contains the users id\n",
    "    item_key: the column in the pandas dataframe that contains the items id\n",
    "    \n",
    "    Returns: (X, user_mapper, item_mapper, user_inverse_mapper, item_inverse_mapper, user_ind, item_ind)\n",
    "    --------\n",
    "    X: the sparse matrix containing the ratings. Note that\n",
    "    user_mapper: stores the indexes of the users - the user_id is the key;\n",
    "    item_mapper: stores the indexes of the items - the item_id is the key;\n",
    "    user_inverse_mapper: stores the user id - the user index is the key;\n",
    "    item_inverse_mapper: stores the item id - the item index is the key;\n",
    "    user_ind: indexes of the users;\n",
    "    item_ind: indexes of the items;\n",
    "    \"\"\"\n",
    "    \n",
    "    user_mapper = dict(zip(np.unique(ratings[user_key]), list(range(d))))\n",
    "    item_mapper = dict(zip(np.unique(ratings[item_key]), list(range(n))))\n",
    "\n",
    "    user_inverse_mapper = dict(zip(list(range(d)), np.unique(ratings[user_key])))\n",
    "    item_inverse_mapper = dict(zip(list(range(n)), np.unique(ratings[item_key])))\n",
    "\n",
    "    user_ind = [user_mapper[i] for i in ratings[user_key]]\n",
    "    item_ind = [item_mapper[i] for i in ratings[item_key]]\n",
    "\n",
    "    X = sparse_matrix((ratings[\"rating\"], (item_ind, user_ind)), shape=(n,d))\n",
    "    \n",
    "    return X, user_mapper, item_mapper, user_inverse_mapper, item_inverse_mapper, user_ind, item_ind\n",
    "\n",
    "X, user_mapper, item_mapper, user_inverse_mapper, item_inverse_mapper, user_ind, item_ind = create_X(ratings, n, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the shape of `X`: our rows are the products, and the columns (features) are the users. So, for each product, the ratings of all users forms the feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105984, 714791)\n",
      "993490\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(X.shape) # should be number of items by number of users\n",
    "print(X.nnz)   # number of nonzero elements -- should equal number of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7947920"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.data.nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Above: our calculation of 8 MB was right on. No surprises there.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's aim to find the following items:\n",
    "\n",
    "- the item with the most reviews\n",
    "- the item with the most total stars\n",
    "- the item with the lowest average stars\n",
    "\n",
    "Then, find the names of these items by looking them up with the url https://www.amazon.com/dp/ITEM_ID, where `ITEM_ID` is the id of the item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.com/dp/B00CFM0P7Y\n"
     ]
    }
   ],
   "source": [
    "url_amazon = \"https://www.amazon.com/dp/%s\"\n",
    "\n",
    "# example:\n",
    "print(url_amazon % 'B00CFM0P7Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_item_info(item):\n",
    "    '''\n",
    "    Function to print movie info\n",
    "    '''\n",
    "    print(\"Item index with most reviews is: {}\".format(item))\n",
    "    print(\"Link to the item:\", url_amazon % item_inverse_mapper[item])\n",
    "    print(\"Average rating: \", X[item].sum(axis = 1)/X[item].getnnz(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item index with most reviews is: 10959\n",
      "Link to the item: https://www.amazon.com/dp/B000HCLLMM\n",
      "Average rating:  [[4.54528302]]\n",
      "Name of the item: Classic Accessories 73942 Veranda Grill Cover, X-Large, Pebble\n"
     ]
    }
   ],
   "source": [
    "# getting the item with most reviews\n",
    "item = np.argmax(X.getnnz(axis = 1))\n",
    "print_item_info(item)\n",
    "print(\"Name of the item: Classic Accessories 73942 Veranda Grill Cover, X-Large, Pebble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item index with most reviews is: 10959\n",
      "Link to the item: https://www.amazon.com/dp/B000HCLLMM\n",
      "Average rating:  [[4.54528302]]\n",
      "Name of the item: Classic Accessories 73942 Veranda Grill Cover, X-Large, Pebble\n"
     ]
    }
   ],
   "source": [
    "# getting the item with most stars\n",
    "item = np.argmax(X.sum(axis = 1))\n",
    "print_item_info(item)\n",
    "print(\"Name of the item: Classic Accessories 73942 Veranda Grill Cover, X-Large, Pebble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item index with most reviews is: 10\n",
      "Link to the item: https://www.amazon.com/dp/6035000037\n",
      "Average rating:  [[1.]]\n",
      "Name of the item: 13ft Sycamore Wood Centre Pole Beige Umbrella Outdoor Patio Beach Market Garden\n"
     ]
    }
   ],
   "source": [
    "# getting the item with lowest average\n",
    "item = np.argmin(X.mean(axis = 1))\n",
    "print_item_info(item)\n",
    "print(\"Name of the item: 13ft Sycamore Wood Centre Pole Beige Umbrella Outdoor Patio Beach Market Garden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a histogram of the number of ratings per user and the number of ratings per item, and comment on the results. You use\n",
    "\n",
    "```\n",
    "plt.yscale('log', nonposy='clip')\n",
    "``` \n",
    "\n",
    "to put the histogram on a log-scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105984, 714791)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105984,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of items\n",
    "X.getnnz(axis = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714791,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of users\n",
    "X.getnnz(axis = 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_hist(X, axis, title=None):\n",
    "    vals = X.getnnz(axis = axis)\n",
    "    plt.hist(vals, bins=20)\n",
    "    label = \"\"\n",
    "    if axis == 1:\n",
    "        label = \"Item ratings\"\n",
    "    else:\n",
    "        label = \"User ratings\"\n",
    "    plt.xlabel(label)\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.yscale('log', nonposy='clip')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram for item ratings\n",
    "make_hist(X, 1)\n",
    "# histogram for user ratings\n",
    "make_hist(X, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mr Grill\n",
    "\n",
    "Use scikit-learn's [NearestNeighbors](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html) object (which uses Euclidean distance by default) to find the 5 items most similar to [MIGO PL-028-8, 8 Pack](https://www.amazon.com/dp/B00CFM0P7Y). \n",
    "\n",
    "(PS: two of these items are not in the Amazon website anymore)\n",
    "\n",
    "Note: if you inspect the above URL, you'll see that the item ID is `B00CFM0P7Y`, which you'll need. The code block below grabs the row of `X` associated with the grill brush. The mappers take care of going back and forther between the IDs (like `B00CFM0P7Y`) and the indices of the sparse array (0,1,2,...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grill_brush = \"B00CFM0P7Y\"\n",
    "grill_brush_ind = item_mapper[grill_brush]\n",
    "grill_brush_vec = X[grill_brush_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearestneighbour(model, X, query_ind, show_ratings = False):\n",
    "    model.fit(X)\n",
    "    query_vec = X[query_ind]\n",
    "    query_vec = query_vec.reshape(1, -1)\n",
    "    query = model.kneighbors(query_vec, 6, return_distance=False)\n",
    "    print(\"Indices of nearest neighbors:\", query[0])\n",
    "    for i in range(1, np.size(query[0])):\n",
    "        ind = query[0][i]\n",
    "        link = item_inverse_mapper[ind]\n",
    "        if not show_ratings:\n",
    "            print(\"Link to the item {}:\".format(i), url_amazon % link)\n",
    "        else:\n",
    "            print(\"Link to the item {}:\".format(i), url_amazon % link, \\\n",
    "                  \"with total ratings: {}\".format( X[query[0][i]].sum(axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of nearest neighbors: [ 93652 103866 103865  98897  72226 102810]\n",
      "Link to the item 1: https://www.amazon.com/dp/B00IJB5MCS\n",
      "Link to the item 2: https://www.amazon.com/dp/B00IJB4MLA\n",
      "Link to the item 3: https://www.amazon.com/dp/B00EXE4O42\n",
      "Link to the item 4: https://www.amazon.com/dp/B00743MZCM\n",
      "Link to the item 5: https://www.amazon.com/dp/B00HVXQY9A\n"
     ]
    }
   ],
   "source": [
    "neigh = NearestNeighbors(n_neighbors=5, metric=\"euclidean\", n_jobs=-1)\n",
    "find_nearestneighbour(neigh, X, grill_brush_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The last two items have been removed from Amazon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine similarity\n",
    "\n",
    "Using cosine similarity instead of Euclidean distance in `NearestNeighbors`, find the 5 products most similar to `B00CFM0P7Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of nearest neighbors: [ 93652 103866 103867 103865  98068  98066]\n",
      "Link to the item 1: https://www.amazon.com/dp/B00IJB5MCS\n",
      "Link to the item 2: https://www.amazon.com/dp/B00IJB8F3G\n",
      "Link to the item 3: https://www.amazon.com/dp/B00IJB4MLA\n",
      "Link to the item 4: https://www.amazon.com/dp/B00EF45AHU\n",
      "Link to the item 5: https://www.amazon.com/dp/B00EF3YF0Y\n"
     ]
    }
   ],
   "source": [
    "# using cosine similarity\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=5, metric=\"cosine\", n_jobs=-1)\n",
    "find_nearestneighbour(neigh, X, grill_brush_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean distance vs. cosine similarity\n",
    "\n",
    "Let's now do the following to further understand our results\n",
    "1. For each of the two metrics, compute the compute the total popularity (total stars) of each of the 5 items and report it. \n",
    "2. What's the difference between Euclidean distance vs. cosine similarity? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of nearest neighbors: [ 93652 103866 103865  98897  72226 102810]\n",
      "Link to the item 1: https://www.amazon.com/dp/B00IJB5MCS with total ratings: [[266.]]\n",
      "Link to the item 2: https://www.amazon.com/dp/B00IJB4MLA with total ratings: [[205.]]\n",
      "Link to the item 3: https://www.amazon.com/dp/B00EXE4O42 with total ratings: [[5.]]\n",
      "Link to the item 4: https://www.amazon.com/dp/B00743MZCM with total ratings: [[5.]]\n",
      "Link to the item 5: https://www.amazon.com/dp/B00HVXQY9A with total ratings: [[5.]]\n"
     ]
    }
   ],
   "source": [
    "# for euclidean case\n",
    "neigh = NearestNeighbors(n_neighbors=5, metric=\"euclidean\", n_jobs=-1)\n",
    "find_nearestneighbour(neigh, X, grill_brush_ind, show_ratings = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of nearest neighbors: [ 93652 103866 103867 103865  98068  98066]\n",
      "Link to the item 1: https://www.amazon.com/dp/B00IJB5MCS with total ratings: [[266.]]\n",
      "Link to the item 2: https://www.amazon.com/dp/B00IJB8F3G with total ratings: [[438.]]\n",
      "Link to the item 3: https://www.amazon.com/dp/B00IJB4MLA with total ratings: [[205.]]\n",
      "Link to the item 4: https://www.amazon.com/dp/B00EF45AHU with total ratings: [[311.]]\n",
      "Link to the item 5: https://www.amazon.com/dp/B00EF3YF0Y with total ratings: [[513.]]\n"
     ]
    }
   ],
   "source": [
    "# for cosine case\n",
    "neigh = NearestNeighbors(n_neighbors=5, metric=\"cosine\", n_jobs=-1)\n",
    "find_nearestneighbour(neigh, X, grill_brush_ind, show_ratings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In high dimensions, most of the points seem to lie on a sphere and with `Cosine` similarity, we are obtaining items that are closer to each other in property as it uses the angles between the objects which make sense considering points lying on a sphere. With `Euclidean` similarity on the other hand, we get total ratings values which are not very close or similar to each other which makes sense because we are using a distance metric for calculating the neighbors and these distances might be similar for very dissimilar points lying in a high-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Items with a reviewer in common\n",
    "\n",
    "In all the above, our feature vectors are the vectors of all the user ratings for a given item. These features are quite sparse: from above we can see that only about $1$ in $100,000$ user-item combinations actually has a rating. As a result, when comparing two items we really don't have a lot of information. For example, what if two items have no users in common whatsoever? (Meaning, there does not exist a user that has rated both items). In this case, the cosine similarity between two such items would be zero, since the cosine similarity is just a normalized dot product, and each term in the dot product is zero (it's worth pondering this until you're sure you understand).\n",
    "\n",
    "Given the above, we'd never connect two such items, although they may in reality be quite similar. For example, we might know item A is very similar to item B and that item B is very similar to item C, but not grasp the connection between A and C because they might not have any ratings in common.\n",
    "\n",
    "Let's try to understand how often this happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have $n$ items which means we have roughly $n^2$ pairs of items. Well, $n(n-1)/2$ to be exact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5616251136"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pairs = n*(n-1)//2\n",
    "num_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the ~5 billion pairs of items in our data set, let's find the fraction of them that have no users in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of items with no users: 0.00014\n"
     ]
    }
   ],
   "source": [
    "# I can get the number of zeros in X.T@X and that will give me the number of dot products that are 0\n",
    "check_nz = X@X.T\n",
    "\n",
    "# the total number of entries should be equal to (num_pairs * 2 + n)\n",
    "# (as num_pairs = number of entries in the lower triangular matrix)\n",
    "\n",
    "(check_nz.shape[0])**2 == num_pairs*2 + n\n",
    "\n",
    "# checking non-zero entries in the matrix\n",
    "print(\"Fraction of items with no users: {:.5f}\".format(check_nz.getnnz(None) / (num_pairs*2 + n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is very low rate for the dot product being zero. I didn't expect this at first but it kind of makes sense as since we have so many items and users, the probability of getting a 0 dot product is very low (which we can see from the above number)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix completion with SVD\n",
    "\n",
    "Let's run collaborative filtering on this data set. \n",
    "\n",
    "**Plan A**: we run PCA on the matrix, and then look at the reconstruction we get from PCA. The reconstruction will be dense, whereas the original matrix is sparse. We can then run nearest neighbours on this dense matrix and hope for better results. But, wait. Didn't we say above that the dense $n \\times n$ matrix is way too big to deal with? Ok, let's try something slightly different. \n",
    "\n",
    "**Plan B**: PCA gives us an approximation\n",
    "\n",
    "$$X \\approx ZW$$\n",
    "\n",
    "where $Z$ is a $n \\times k$ matrix of \"factor loadings\" and $W$ is a $k \\times d$ matrix of our principal components or \"factors\". (So we've actually got a [low-rank approximation](https://en.wikipedia.org/wiki/Low-rank_approximation) to our original matrix $X$).\n",
    "\n",
    "Let's use a fairly small value of $k$, and then do our nearest neighbours on the $Z$ matrix. We can give this a shot with $k=10$ again using the NearestNeighbors class with Euclidean distance. You can use scikit-learn's [TruncatedSVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html) to perform the dimensionality reduction. (We want a truncated rather than full SVD since a full SVD would involve $n\\times n$ matrices, which we've already established are too big to deal with. And then we'd only use the first $k$ rows of it anyway. So a full SVD would be both impossible and pointless.) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105984, 714791)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105984, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=10, n_iter=10, random_state=42)\n",
    "svd.fit(X)\n",
    "Z = svd.transform(X)\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of nearest neighbors: [93652 13756 10620 31819 19540 27755]\n",
      "Link to the item 1: https://www.amazon.com/dp/B000MVLB8W\n",
      "Link to the item 2: https://www.amazon.com/dp/B000H1SJ8C\n",
      "Link to the item 3: https://www.amazon.com/dp/B001VNC3Q4\n",
      "Link to the item 4: https://www.amazon.com/dp/B000X9BNG8\n",
      "Link to the item 5: https://www.amazon.com/dp/B001H1NG1Q\n"
     ]
    }
   ],
   "source": [
    "# for euclidean case\n",
    "neigh = NearestNeighbors(n_neighbors=5, metric=\"euclidean\", n_jobs=-1)\n",
    "find_nearestneighbour(neigh, Z, grill_brush_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Looking at the results, the transformation into a smaller dimension subspace to get a dense matrix and then using the nearest neighbors with euclidean metric seems to give a better result than what we got earlier with euclidean metric. The items seem to be similar and closely related (grill and outdoor cooking category)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie recommendations\n",
    "\n",
    "\n",
    "\n",
    "For this part of the notebook I'm gonna use the [MovieLens](https://grouplens.org/datasets/movielens/) dataset. We'll use the small version of the data set which you can download [here](http://files.grouplens.org/datasets/movielens/ml-latest-small.zip). Please download it and put the unzipped directory in your `data` directory. The structure of the data is described in the [README](http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html) that comes with the data. \n",
    "\n",
    "\n",
    "The loading and parsing of the data is done for you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ratings = pd.read_csv(os.path.join(\"/Users/arzan/MDS\", \"ml-latest-small\", \"ratings.csv\"))\n",
    "movie_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 100836\n",
      "The average rating: 3.501556983616962\n",
      "Number of users: 610\n",
      "Number of items: 9724\n",
      "Fraction nonzero: 0.016999683055613623\n",
      "Size of full X matrix (GB): 0.04745312\n"
     ]
    }
   ],
   "source": [
    "movie_n, movie_d = get_stats(movie_ratings, user_key=\"userId\", item_key=\"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_X, user_mapper, movie_mapper, user_inverse_mapper, movie_inverse_mapper, user_ind, \\\n",
    "movie_ind = create_X(movie_ratings, movie_n, movie_d, user_key=\"userId\", item_key=\"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_story_ind = 0\n",
    "toy_story_vec = movie_X[toy_story_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title  \\\n",
       "movieId                                       \n",
       "1                          Toy Story (1995)   \n",
       "2                            Jumanji (1995)   \n",
       "3                   Grumpier Old Men (1995)   \n",
       "4                  Waiting to Exhale (1995)   \n",
       "5        Father of the Bride Part II (1995)   \n",
       "\n",
       "                                              genres  \n",
       "movieId                                               \n",
       "1        Adventure|Animation|Children|Comedy|Fantasy  \n",
       "2                         Adventure|Children|Fantasy  \n",
       "3                                     Comedy|Romance  \n",
       "4                               Comedy|Drama|Romance  \n",
       "5                                             Comedy  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to look up titles\n",
    "movie_info = pd.read_csv(os.path.join(\"/Users/arzan/MDS\", \"ml-latest-small\", \"movies.csv\"),index_col=0)\n",
    "movie_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of the MIGO PL-028-8, 8 Pack, let's instead use our \"query item\" as _Toy Story_, which is the first movie in the list (`movieId`=1). Like with Amazon, you can look up the recommended movies by looking at the `links.csv` file, which gives you the IMDB id of each movie, allowing you to form a URL of the form http://www.imdb.com/title/ttXXXXXXX/ where `XXXXXXX` is the movie's IMDB id. However, that extra work isn't really necessary here since we have a second table mapping `movieId` to movie title, so you can just grab the titles and print them out directly (see below).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0114709</td>\n",
       "      <td>862.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0113497</td>\n",
       "      <td>8844.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0113228</td>\n",
       "      <td>15602.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0114885</td>\n",
       "      <td>31357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0113041</td>\n",
       "      <td>11862.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          imdbId   tmdbId\n",
       "movieId                  \n",
       "1        0114709    862.0\n",
       "2        0113497   8844.0\n",
       "3        0113228  15602.0\n",
       "4        0114885  31357.0\n",
       "5        0113041  11862.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to look up links\n",
    "movie_links = pd.read_csv(os.path.join(\"/Users/adityasharma/Desktop\", \\\n",
    "                                       \"ml-latest-small\", \"links.csv\"), index_col=0, dtype={'imdbId': object})\n",
    "movie_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_imdb = \"http://www.imdb.com/title/tt%s\"\n",
    "\n",
    "def print_movie_info(item):\n",
    "    '''\n",
    "    Function to print movie info\n",
    "    '''\n",
    "    print(\"Movie index is: {}\".format(item))\n",
    "    print(\"The movie details are: {}\".format(movie_info[movie_info.index.values == movie_inverse_mapper[item]]))\n",
    "    print(\"Link to the movie:\", \n",
    "          url_imdb % movie_links[movie_info.index.values == movie_inverse_mapper[item]].loc[:, 'imdbId'].values[0])\n",
    "    print(\"Average rating:\", movie_X[item].sum(axis = 1)/movie_X[item].getnnz(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie index is: 314\n",
      "The movie details are:                        title                    genres\n",
      "movieId                                               \n",
      "356      Forrest Gump (1994)  Comedy|Drama|Romance|War\n",
      "Link to the movie: http://www.imdb.com/title/tt0109830\n",
      "Average rating: [[4.16413374]]\n"
     ]
    }
   ],
   "source": [
    "# getting the movie with most reviews\n",
    "item = np.argmax(movie_X.getnnz(axis = 1))\n",
    "\n",
    "print_movie_info(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie index is: 277\n",
      "The movie details are:                                     title       genres\n",
      "movieId                                               \n",
      "318      Shawshank Redemption, The (1994)  Crime|Drama\n",
      "Link to the movie: http://www.imdb.com/title/tt0111161\n",
      "Average rating: [[4.42902208]]\n"
     ]
    }
   ],
   "source": [
    "# getting the movie with most total stars\n",
    "item = np.argmax(movie_X.sum(axis = 1))\n",
    "print_movie_info(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie index is: 2685\n",
      "The movie details are:                 title   genres\n",
      "movieId                       \n",
      "3604     Gypsy (1962)  Musical\n",
      "Link to the movie: http://www.imdb.com/title/tt0056048\n",
      "Average rating: [[0.5]]\n"
     ]
    }
   ],
   "source": [
    "# getting the movie with lowest average stars\n",
    "item = np.argmin(movie_X.mean(axis = 1))\n",
    "print_movie_info(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# function already there for histogram (directly calling)\n",
    "\n",
    "# histogram for movie ratings\n",
    "make_hist(movie_X, 1)\n",
    "# histogram for user ratings\n",
    "make_hist(movie_X, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearestneighbour_imdb(model, X, query_ind, show_ratings = False):\n",
    "    model.fit(X)\n",
    "    query_vec = X[query_ind]\n",
    "    query_vec = query_vec.reshape(1, -1)\n",
    "    query = model.kneighbors(query_vec, 6, return_distance=False)\n",
    "    print(\"Indices of nearest neighbors:\", query[0])\n",
    "    print(\"The nearest neighbors are: \\n\")\n",
    "    for i in range(1, np.size(query[0])):\n",
    "        ind = query[0][i]\n",
    "        link = movie_links.iloc[ind]['imdbId']\n",
    "        name = movie_info.iloc[ind]['title']\n",
    "        if not show_ratings:\n",
    "            print(\"{0}\".format(name), url_imdb % link)\n",
    "        else:\n",
    "            print(\"{0}\".format(name), url_imdb % link, \\\n",
    "                  \"Total ratings: {}\".format(X[query[0][i]].sum(axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of nearest neighbors: [   0 2353  546  615 1756  622]\n",
      "The nearest neighbors are: \n",
      "\n",
      "'night Mother (1986) http://www.imdb.com/title/tt0090556\n",
      "Mission: Impossible (1996) http://www.imdb.com/title/tt0117060\n",
      "Independence Day (a.k.a. ID4) (1996) http://www.imdb.com/title/tt0116629\n",
      "Rugrats Movie, The (1998) http://www.imdb.com/title/tt0134067\n",
      "Nutty Professor, The (1996) http://www.imdb.com/title/tt0117218\n"
     ]
    }
   ],
   "source": [
    "# euclidean\n",
    "neigh = NearestNeighbors(n_neighbors=5, metric=\"euclidean\", n_jobs=-1)\n",
    "find_nearestneighbour_imdb(neigh, movie_X, toy_story_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of nearest neighbors: [   0 2353  418  615  224  314]\n",
      "The nearest neighbors are: \n",
      "\n",
      "'night Mother (1986) http://www.imdb.com/title/tt0090556\n",
      "Jurassic Park (1993) http://www.imdb.com/title/tt0107290\n",
      "Independence Day (a.k.a. ID4) (1996) http://www.imdb.com/title/tt0116629\n",
      "Star Wars: Episode IV - A New Hope (1977) http://www.imdb.com/title/tt0076759\n",
      "Forrest Gump (1994) http://www.imdb.com/title/tt0109830\n"
     ]
    }
   ],
   "source": [
    "# cosine\n",
    "neigh = NearestNeighbors(n_neighbors=5, metric=\"cosine\", n_jobs=-1)\n",
    "find_nearestneighbour_imdb(neigh, movie_X, toy_story_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of nearest neighbors: [   0 2353  546  615 1756  622]\n",
      "The nearest neighbors are: \n",
      "\n",
      "'night Mother (1986) http://www.imdb.com/title/tt0090556 Total ratings: [[374.5]]\n",
      "Mission: Impossible (1996) http://www.imdb.com/title/tt0117060 Total ratings: [[573.]]\n",
      "Independence Day (a.k.a. ID4) (1996) http://www.imdb.com/title/tt0116629 Total ratings: [[696.]]\n",
      "Rugrats Movie, The (1998) http://www.imdb.com/title/tt0134067 Total ratings: [[323.5]]\n",
      "Nutty Professor, The (1996) http://www.imdb.com/title/tt0117218 Total ratings: [[224.]]\n"
     ]
    }
   ],
   "source": [
    "# euclidean with total stars\n",
    "neigh = NearestNeighbors(n_neighbors=5, metric=\"euclidean\", n_jobs=-1)\n",
    "find_nearestneighbour_imdb(neigh, movie_X, toy_story_ind, show_ratings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of nearest neighbors: [   0 2353  418  615  224  314]\n",
      "The nearest neighbors are: \n",
      "\n",
      "'night Mother (1986) http://www.imdb.com/title/tt0090556 Total ratings: [[374.5]]\n",
      "Jurassic Park (1993) http://www.imdb.com/title/tt0107290 Total ratings: [[892.5]]\n",
      "Independence Day (a.k.a. ID4) (1996) http://www.imdb.com/title/tt0116629 Total ratings: [[696.]]\n",
      "Star Wars: Episode IV - A New Hope (1977) http://www.imdb.com/title/tt0076759 Total ratings: [[1062.]]\n",
      "Forrest Gump (1994) http://www.imdb.com/title/tt0109830 Total ratings: [[1370.]]\n"
     ]
    }
   ],
   "source": [
    "# cosine with total stars\n",
    "neigh = NearestNeighbors(n_neighbors=5, metric=\"cosine\", n_jobs=-1)\n",
    "find_nearestneighbour_imdb(neigh, movie_X, toy_story_ind, show_ratings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of nearest neighbors: [  0 615 968 418 506 546]\n",
      "The nearest neighbors are: \n",
      "\n",
      "Independence Day (a.k.a. ID4) (1996) http://www.imdb.com/title/tt0116629\n",
      "Arsenic and Old Lace (1944) http://www.imdb.com/title/tt0036613\n",
      "Jurassic Park (1993) http://www.imdb.com/title/tt0107290\n",
      "Aladdin (1992) http://www.imdb.com/title/tt0103639\n",
      "Mission: Impossible (1996) http://www.imdb.com/title/tt0117060\n"
     ]
    }
   ],
   "source": [
    "# using transformation through SVD\n",
    "svd = TruncatedSVD(n_components=10, n_iter=10, random_state=42)\n",
    "svd.fit(movie_X)\n",
    "Z = svd.transform(movie_X)\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=5, metric=\"euclidean\", n_jobs=-1)\n",
    "find_nearestneighbour_imdb(neigh, Z, toy_story_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things that would be too slow with the Amazon dataset\n",
    "\n",
    "1. Let's increase $k$ (the number of components of the SVD) and see what happens to the recommendations, as compared to the Euclidean nearest neighbour recommendations, when $k$ is large and try . to explain this result mathematically.\n",
    "2. Something we can do with the SVD that we can't do with nearest neighbours is to predict missing ratings. For example, user 5 has not rated Toy Story. We can use the SVD to predict this rating, using the `inverse_transform` function of the `TruncatedSVD` class. \n",
    "3. Because of the size of the amazon data, the process in step is extremely slow. The problem is unavoidable if we want to predict all the missing ratings. However, if we really did just want to predict a single rating we could do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 20\n",
      "Indices of nearest neighbors: [  0 506 968 963 418 815]\n",
      "The nearest neighbors are: \n",
      "\n",
      "Aladdin (1992) http://www.imdb.com/title/tt0103639\n",
      "Arsenic and Old Lace (1944) http://www.imdb.com/title/tt0036613\n",
      "Diva (1981) http://www.imdb.com/title/tt0082269\n",
      "Jurassic Park (1993) http://www.imdb.com/title/tt0107290\n",
      "Willy Wonka & the Chocolate Factory (1971) http://www.imdb.com/title/tt0067992\n",
      "-----------------------------------------\n",
      "K = 220\n",
      "Indices of nearest neighbors: [   0 2353  615  546   32  325]\n",
      "The nearest neighbors are: \n",
      "\n",
      "'night Mother (1986) http://www.imdb.com/title/tt0090556\n",
      "Independence Day (a.k.a. ID4) (1996) http://www.imdb.com/title/tt0116629\n",
      "Mission: Impossible (1996) http://www.imdb.com/title/tt0117060\n",
      "Babe (1995) http://www.imdb.com/title/tt0112431\n",
      "Mask, The (1994) http://www.imdb.com/title/tt0110475\n",
      "-----------------------------------------\n",
      "K = 420\n",
      "Indices of nearest neighbors: [   0 2353  546  615  622 1756]\n",
      "The nearest neighbors are: \n",
      "\n",
      "'night Mother (1986) http://www.imdb.com/title/tt0090556\n",
      "Mission: Impossible (1996) http://www.imdb.com/title/tt0117060\n",
      "Independence Day (a.k.a. ID4) (1996) http://www.imdb.com/title/tt0116629\n",
      "Nutty Professor, The (1996) http://www.imdb.com/title/tt0117218\n",
      "Rugrats Movie, The (1998) http://www.imdb.com/title/tt0134067\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# increasing k with SVD\n",
    "for k in range(20, 600, 200):\n",
    "    print(\"K = {}\".format(k))\n",
    "    svd = TruncatedSVD(n_components=k, n_iter=10, random_state=42)\n",
    "    svd.fit(movie_X)\n",
    "    Z = svd.transform(movie_X)\n",
    "\n",
    "    neigh = NearestNeighbors(n_neighbors=5, metric=\"euclidean\", n_jobs=-1)\n",
    "    find_nearestneighbour_imdb(neigh, Z, toy_story_ind)\n",
    "    print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We see that the recommendations on increasing $k$ for SVD become close to what the actual recommendations are which can be measured by checking the example given for user 5 and toy story. This makes sense as we are trying to learn a low dimensional representation with SVD and on increasing $k$, we are learning the same information in more dimensions and the algorithm tries to incorporate the contribution of many reconstructed dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting original rating:\n",
      "4.0\n",
      "getting constructed rating for user 5 for toy story, k = 200:\n",
      "2.413488464104162\n",
      "getting constructed rating for user 5 for toy story, k = 300:\n",
      "3.3472874523990916\n",
      "getting constructed rating for user 5 for toy story, k = 400:\n",
      "3.9871429092584494\n"
     ]
    }
   ],
   "source": [
    "# transforming to a new dimension representation\n",
    "print(\"getting original rating:\")\n",
    "print(movie_X[0, 4])\n",
    "for n in [200, 300, 400]:\n",
    "    svd = TruncatedSVD(n_components=n, n_iter=10, random_state=12345)\n",
    "    svd.fit(movie_X)\n",
    "    Z = svd.transform(movie_X)\n",
    "    movie_new = svd.inverse_transform(Z)\n",
    "    Z.shape\n",
    "\n",
    "    print(\"getting constructed rating for user 5 for toy story, k = {}:\". format(n))\n",
    "    print(movie_new[0, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example shows that the reconstruction is better with increasing $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** The amazon data is very huge and it would require a lot of time go through this process for such a large dataset. Let us try to do it for a single user and item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_X = X[0:10, :]\n",
    "svd = TruncatedSVD(n_components=200, n_iter=10, random_state=12345)\n",
    "svd.fit(sub_X)\n",
    "Z = svd.transform(sub_X)\n",
    "movie_new = svd.inverse_transform(Z)\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4316688435111548e-18"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconstructed rating\n",
    "movie_new[9,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tease\n",
    "\n",
    "For each of the following methods, let's understand how it might be applied to the problem of item recommendation:\n",
    "\n",
    "1. Clustering\n",
    "2. Graphs and breadth-first search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Clustering**: For item recommendation, we could cluster items closer to each other in the feature space as having similar properties which is what we do above with euclidean distance. If we cluster the items after proper transformation, we will get meaningful clusters that will have some common property like how we found after using dimensionality reduction using SVD with euclidean distance for the amazon dataset.\n",
    "\n",
    "2. **Graphs and breadth-first search**: If we try to use graph algorithms such as BFS, we can star with one item in the feature space and decide a fixed depth $d$ until which we will consider items as similar to the original item. Now performing BFS, all the items within a distance less than or equal to this number $d$ will be considered similar and can be recommended to the users that liked/rated high items falling in this group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are we creating a bubble?\n",
    "We've been using similarity as a proxy for things we want to recommend. However, this has its own disadvantages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Recommending similar items is often a good idea but not always the best strategy to tackle market growth. People might get bored of similar items/movies/products etc. and it would be good to recommend something new and different once in a while so that people get to try new things. This would keep them interested in what the algorithm/company has to offer to them and would lead to more user engagement overall. For example, if a user watched Harry Potter 1, it would be a good idea to not just recommend all the HP series and instead provide some different fantasy options as well like Lord of the Rings, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative ways to recommend\n",
    "\n",
    "Another way to recommend items, say movies on Netflix, is to use something like the SVD to fill in the missing entries, and then for each user take the movies for which the predicted ratings is highest. In other words, I'll recommend the movies that I think you'll rate highly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using this approach, we are trying to learn patterns from the data and trying to represent them in lower dimensions where we don't have missing values. Therefore, this approach is making the use of what the algorithm thinks are similar items. An approach using nearest neighbors on the other hand, depends on other people ratings for the similarity measure. In this case, we will rate items as similar if people with similar item choices have rated those items with similar ratings. So both the approaches differ in their sources of obtaining the missing values of the ratings. Use cases would depend on the size of the data. More items and users would lead to higher dimensions where SVD would give better results. But in cases with smaller dimensions and when we want to recommend based on similar users and their choices, we could go for nearest neighbors. I think the better approach is to find a lower $k$-dimensional representation of the original data which best reconstructs the original data using SVD. This is better than finding clusters in high dimensions which might not give reliable results with distance metrics as a measure of similarity."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
